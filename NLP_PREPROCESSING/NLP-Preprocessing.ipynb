{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "628640a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>Imprisoned in the 1940s for the double murder ...</td>\n",
       "      <td>Drama, Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>Spanning the years 1945 to 1955, a chronicle o...</td>\n",
       "      <td>Drama, Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>In the continuing saga of the Corleone crime f...</td>\n",
       "      <td>Drama, Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>The true story of how businessman Oskar Schind...</td>\n",
       "      <td>Drama, History, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>The defense and the prosecution have rested an...</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  \\\n",
       "0  The Shawshank Redemption   \n",
       "1             The Godfather   \n",
       "2     The Godfather Part II   \n",
       "3          Schindler's List   \n",
       "4              12 Angry Men   \n",
       "\n",
       "                                            overview               genres  \n",
       "0  Imprisoned in the 1940s for the double murder ...         Drama, Crime  \n",
       "1  Spanning the years 1945 to 1955, a chronicle o...         Drama, Crime  \n",
       "2  In the continuing saga of the Corleone crime f...         Drama, Crime  \n",
       "3  The true story of how businessman Oskar Schind...  Drama, History, War  \n",
       "4  The defense and the prosecution have rested an...                Drama  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"movies.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ef5c2c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"]=df[\"title\"]+ \" \" + df[\"overview\"]\n",
    "df.drop(columns=[\"title\",\"overview\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "10eefec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\R.C\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\R.C\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "stop_words=set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text=str(text).lower()\n",
    "    # Remove html tags\n",
    "    text=re.sub(r\"<.*?>\",\" \", text)\n",
    "    # Remove URL\n",
    "    text=re.sub(r\"http\\S+|www\\S+|https\\S+\",\" \",text)\n",
    "    # Remove Punctuation\n",
    "    text=text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "    # Tokenize\n",
    "    words=word_tokenize(text)\n",
    "    # Stopwords Removal\n",
    "    words=[word for word in words if word not in stop_words] \n",
    "    # Lemmatization\n",
    "    words=[lemmatizer.lemmatize(word) for word in words]\n",
    "    # join back to string\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c467306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply preprocessing\n",
    "df['text']=df[\"text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "49cd4cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genres    3\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "750dfe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"genres\"]=df[\"genres\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a191fb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genres    0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f1104bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[\"text\"]\n",
    "binarizer=MultiLabelBinarizer()\n",
    "y=binarizer.fit_transform(df[\"genres\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "8eae3fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d227c465",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer(max_features=5000)\n",
    "X_train=vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "24c747c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=OneVsRestClassifier(LogisticRegression(max_iter=2000))\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d6c8b7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "                   0.87      1.00      0.93      1481\n",
      "           ,       0.87      1.00      0.93      1480\n",
      "           A       0.82      0.58      0.68       594\n",
      "           C       0.72      0.67      0.69       792\n",
      "           D       0.71      0.71      0.71       855\n",
      "           F       0.86      0.46      0.60       465\n",
      "           H       0.86      0.13      0.23       327\n",
      "           M       0.73      0.04      0.07       212\n",
      "           R       0.81      0.24      0.37       301\n",
      "           S       0.96      0.23      0.37       186\n",
      "           T       0.73      0.31      0.43       475\n",
      "           V       0.00      0.00      0.00        16\n",
      "           W       1.00      0.08      0.15        84\n",
      "           a       0.75      0.94      0.83      1200\n",
      "           c       0.74      0.62      0.67       810\n",
      "           d       0.69      0.63      0.66       766\n",
      "           e       0.83      1.00      0.90      1410\n",
      "           h       0.74      0.29      0.42       461\n",
      "           i       0.76      0.90      0.82      1092\n",
      "           l       0.66      0.39      0.49       640\n",
      "           m       0.83      0.99      0.90      1397\n",
      "           n       0.73      0.81      0.77       999\n",
      "           o       0.79      1.00      0.88      1345\n",
      "           r       0.86      0.99      0.92      1448\n",
      "           s       0.66      0.20      0.31       475\n",
      "           t       0.76      0.81      0.78       916\n",
      "           u       0.73      0.18      0.29       335\n",
      "           v       0.73      0.18      0.29       299\n",
      "           y       0.67      0.80      0.73       951\n",
      "\n",
      "   micro avg       0.78      0.76      0.77     21812\n",
      "   macro avg       0.75      0.56      0.58     21812\n",
      "weighted avg       0.78      0.76      0.74     21812\n",
      " samples avg       0.78      0.78      0.75     21812\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Conda\\envs\\Machine_Learning\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "e:\\Conda\\envs\\Machine_Learning\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# predict porbabilities\n",
    "y_pred_prob=model.predict_proba(X_test)\n",
    "# Convert to binary prediction\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred, target_names=binarizer.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2563a333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine_Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
